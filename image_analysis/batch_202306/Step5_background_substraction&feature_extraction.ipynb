{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "crucial-converter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDate: 20230712\\nAim: background subtraction using images with water\\nAuthor: Yike Xie\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Date: 20230712\n",
    "Aim: background subtraction using images with water\n",
    "Author: Yike Xie\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "foster-bernard",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import filters\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-toolbox",
   "metadata": {},
   "source": [
    "# background substraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cloudy-playing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_labels(seg_fn):\n",
    "    # label roughly segmented cells by ilastik according to their size\n",
    "    print('import segmentated figure')\n",
    "    seg = cv2.imread(seg_fn, 2)\n",
    "\n",
    "    print('get labels of each cell')\n",
    "    from scipy import ndimage as ndi\n",
    "    seg = ndi.binary_fill_holes(seg - 1)\n",
    "\n",
    "    labeled, _ = ndi.label(seg)\n",
    "    return seg, labeled\n",
    "\n",
    "\n",
    "def crop_ROI(antt, cell, width, height, labeled, pxs):\n",
    "\n",
    "    print('find ROI...')\n",
    "    seg = (labeled == pxs[antt])\n",
    "\n",
    "    i0s = seg.any(axis=1).nonzero()[0]\n",
    "    i1s = seg.any(axis=0).nonzero()[0]\n",
    "    i00, i01 = i0s[0], i0s[-1] + 1\n",
    "    i10, i11 = i1s[0], i1s[-1] + 1\n",
    "\n",
    "    print('add margins...')\n",
    "    margin_px1 = int((width - (i01 - i00)) / 2)\n",
    "    margin_px2 = int((height - (i11 - i10)) / 2)\n",
    "    margin_px = max(margin_px1, margin_px2)\n",
    "    \n",
    "    i00 = max(0, i00 - margin_px)\n",
    "    i10 = max(0, i10 - margin_px)\n",
    "    i01 = min(seg.shape[0], i01 + margin_px)\n",
    "    i11 = min(seg.shape[1], i11 + margin_px)\n",
    "    \n",
    "    return i00, i10, i01, i11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "described-competition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create image array\n",
    "def img_array(img):\n",
    "    files = ['wls_325_414',\n",
    "             'wls_343_414',\n",
    "             'wls_370_414',\n",
    "             'wls_343_451',\n",
    "             'wls_370_451',\n",
    "             'wls_373_451',\n",
    "             'wls_343_575',\n",
    "             'wls_393_575',\n",
    "             'wls_406_575',\n",
    "             'wls_441_575',\n",
    "             'wls_400_594',\n",
    "             'wls_406_594',\n",
    "             'wls_431_594',\n",
    "             'wls_480_594',\n",
    "             'wls_339_575']\n",
    "    \n",
    "    data = np.empty([15] + list(img[files[0]].shape))\n",
    "    \n",
    "    for i, file in enumerate(files):\n",
    "        data[i] = img[file].astype('uint16')\n",
    "        \n",
    "    return data # type uint16\n",
    "\n",
    "# image blurring\n",
    "from skimage.filters import gaussian\n",
    "def blur(img, sigma=1, axis=0):\n",
    "    blurred_img = gaussian(img, sigma=sigma, truncate=3.5, channel_axis=axis, preserve_range=True)\n",
    "    return blurred_img # type uint16\n",
    "\n",
    "# background subtraction\n",
    "def subtract(img, blurred_B):\n",
    "    subtracted_img = (img - blurred_B)\n",
    "    return subtracted_img\n",
    "\n",
    "# image saving\n",
    "def save_npz(img, brightfield, mask, name, path=False):\n",
    "    img_dic = {}\n",
    "    files = ['wls_325_414',\n",
    "             'wls_343_414',\n",
    "             'wls_370_414',\n",
    "             'wls_343_451',\n",
    "             'wls_370_451',\n",
    "             'wls_373_451',\n",
    "             'wls_343_575',\n",
    "             'wls_393_575',\n",
    "             'wls_406_575',\n",
    "             'wls_441_575',\n",
    "             'wls_400_594',\n",
    "             'wls_406_594',\n",
    "             'wls_431_594',\n",
    "             'wls_480_594',\n",
    "             'wls_339_575']\n",
    "    \n",
    "    for i, file in enumerate(files):\n",
    "        img_dic[file] = img[i]\n",
    "        \n",
    "    img_dic['brightfield'] = brightfield\n",
    "    img_dic['segmentation'] = mask\n",
    "    \n",
    "    \n",
    "    if path is not False:\n",
    "        np.savez_compressed(path + name + '.npz', **img_dic) # type uint16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "grateful-valentine",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    # sequenced single cells\n",
    "    # load cropped single cells\n",
    "    figure_npz_fdn = '/home/yike/phd/cancer_cells_img_seq/data/202306_imaging/'\n",
    "    fdn_cell = '/home/yike/phd/cancer_cells_img_seq/figures/batch_202306/cropped_cell_npz/good/'\n",
    "    ilastik_seg = '/home/yike/phd/cancer_cells_img_seq/figures/batch_202306/fake_RGB_images/picked_figures/'\n",
    "    fdn_save = '/home/yike/phd/cancer_cells_img_seq/figures/batch_202306/background_substraction/'\n",
    "\n",
    "    ## load cell annotation information\n",
    "    df = pd.read_csv('/home/yike/phd/cancer_cells_img_seq/figures/batch_202306/fake_RGB_images/cell_annotation/cell_annotation.tsv', \n",
    "              sep='\\t', index_col=0)\n",
    "    sig_df = df[df['Cell_number'] == 1]\n",
    "    sig_df['Mask'] = sig_df['Batch'].astype(str) + sig_df['Grid']\n",
    "    ncells = len(df[df['Cell_number'] == 1].index)\n",
    "\n",
    "if True:\n",
    "    # dapi bright cells\n",
    "    # load cropped single cells\n",
    "    figure_npz_fdn = '/home/yike/phd/cancer_cells_img_seq/data/202306_imaging/'\n",
    "    fdn_cell = '/home/yike/phd/cancer_cells_img_seq/figures/batch_202306/dapi_cropped_cell_npz/'\n",
    "    ilastik_seg = '/home/yike/phd/cancer_cells_img_seq/figures/batch_202306/fake_RGB_images/'\n",
    "    fdn_save = '/home/yike/phd/cancer_cells_img_seq/figures/batch_202306/dapi_background_substraction/'\n",
    "\n",
    "    ## load cell annotation information\n",
    "    df = pd.read_csv('/home/yike/phd/cancer_cells_img_seq/figures/batch_202306/merge_dapi_bf/dapi_cell_annotation.tsv', \n",
    "              sep='\\t')\n",
    "    df['Mask'] = df['Batch'].astype(str) + df['Grid'] + '_' + df['Cell_annotation'].astype(str)\n",
    "    df['Cell'] = df['Mask']\n",
    "    df = df.set_index('Cell')\n",
    "\n",
    "    blur_images = ['20230620Dish1_H7_1',\n",
    "                   '20230620Dish1_H7_2',\n",
    "                   '20230620Dish1_H7_3',\n",
    "                   '20230622Dish2_J2_3',\n",
    "                   '20230622Dish2_J2_4',\n",
    "                   '20230622Dish6_O17_1'\n",
    "                ]\n",
    "    df = df.loc[~ df.index.isin(blur_images)]\n",
    "    \n",
    "    sig_df = df.copy()\n",
    "    ncells = sig_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "proud-mixture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# background substraction\n",
    "i = 0\n",
    "picked_fns = os.listdir(ilastik_seg + 'picked_figures/')\n",
    "unpicked_fns = os.listdir(ilastik_seg + 'unpicked_figures/')\n",
    "\n",
    "for batch in [20230620, 20230621, 20230622]:\n",
    "batch_fdn = os.path.join(figure_npz_fdn, str(batch) + '_imaging')\n",
    "w_fns = [i for i in os.listdir(batch_fdn) if 'Water' in i]\n",
    "\n",
    "print('loading water...')\n",
    "water1 = img_array(np.load(os.path.join(batch_fdn, w_fns[0])))\n",
    "water2 = img_array(np.load(os.path.join(batch_fdn, w_fns[1])))\n",
    "\n",
    "for mask in sig_df[sig_df['Batch'] == batch]['Mask'].unique():\n",
    "    grid = mask.split('_')[0] + '_' + mask.split('_')[1]\n",
    "    print('loading...')\n",
    "    _, labeled = cell_labels(os.path.join(\n",
    "        ilastik_seg + ['unpicked_figures/', 'picked_figures/'][grid + '_Simple Segmentation.tiff' in picked_fns], \n",
    "        grid + '_Simple Segmentation.tiff'))\n",
    "    pxs = np.bincount(labeled.ravel()).argsort()[::-1]\n",
    "\n",
    "    for c, row in sig_df[sig_df['Mask'] == mask].iterrows():\n",
    "        i += 1\n",
    "        print(f'{i + 1}: {c}')\n",
    "\n",
    "        antt = int(row['Cell_annotation'])\n",
    "\n",
    "        cell_npz = np.load(os.path.join(fdn_cell, c + '.npz'))\n",
    "        cell = img_array(cell_npz) # unit16\n",
    "        _, w, h = cell.shape\n",
    "\n",
    "        print('crop...')\n",
    "        i00, i10, i01, i11 = crop_ROI(antt, c, w, h, labeled, pxs)\n",
    "\n",
    "        ctl1 = water1[:, i00: i01, i10: i11] # unit16\n",
    "        ctl2 = water2[:, i00: i01, i10: i11] # unit16\n",
    "\n",
    "        print('blur water...')\n",
    "        bl_ctl1 = blur(ctl1, sigma=1, axis=0)\n",
    "        bl_ctl2 = blur(ctl2, sigma=1, axis=0)\n",
    "\n",
    "        print('background subtraction...')\n",
    "        sb_cell = subtract(cell, (bl_ctl1 + bl_ctl2) / 2)\n",
    "\n",
    "        print('blur cell')\n",
    "        bl_cell = blur(sb_cell)\n",
    "\n",
    "        print('save as npz')\n",
    "        brightfield = cell_npz['brightfield']\n",
    "        mask = cell_npz['new_segmentation']\n",
    "\n",
    "        save_npz(bl_cell, brightfield, mask, c, path=fdn_save)   \n",
    "\n",
    "        print('-------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-dispatch",
   "metadata": {},
   "source": [
    "# feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "spoken-consistency",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(fdn_sub, fdn_seg, fn):\n",
    "    img = np.load(os.path.join(fdn_sub, fn))\n",
    "    mask = img['segmentation']\n",
    "    seg_img = np.load(os.path.join(fdn_seg, fn))\n",
    "    \n",
    "    # Area\n",
    "    area = mask.sum()\n",
    "    # Horizontal length\n",
    "    length = mask.any(axis=0).nonzero()[0]\n",
    "    length = length[-1] - length[0]\n",
    "    # Vertical width (waist line)\n",
    "    width = mask.any(axis=1).nonzero()[0]\n",
    "    width = width[-1] - width[0]\n",
    "    # Eccentricity\n",
    "    ecc = length / width\n",
    "\n",
    "    # Wavelengths\n",
    "    wls = [(int(wl.split('_')[1]), int(wl.split('_')[2])) for wl in img.files[:-2]]\n",
    "    \n",
    "    # Total Intensity\n",
    "    total_int = [(img[wl] * mask).sum() for wl in img.files[:-2]]\n",
    "    \n",
    "    # Average Intensity\n",
    "    ave_int = [int_i/area for int_i in total_int]\n",
    "    \n",
    "    # spectra\n",
    "    spectra = [(seg_img[wl] * mask).sum() for wl in img.files[:-2]]\n",
    "    \n",
    "    feas = {\n",
    "        'area': area,\n",
    "        'length': length,\n",
    "        'width': width,\n",
    "        'eccentricity': ecc,\n",
    "        'image': fn.split('/')[-1].split('.')[0],\n",
    "        'wavelengths': wls,\n",
    "        'spectra': spectra, # w/o background substraction\n",
    "        'total_intensity': total_int, # w/ background substraction\n",
    "        'ave_intensity': ave_int, # w/ background substraction\n",
    "    }\n",
    "\n",
    "    return feas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "driving-wings",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 cell: 20230621Dish5_H8_4\n",
      "2 cell: 20230622Dish5_N14_6\n",
      "3 cell: 20230622Dish3_N10_9\n",
      "4 cell: 20230621Dish5_G13_3\n",
      "5 cell: 20230620Dish4_O12_5\n",
      "6 cell: 20230622Dish4_H12_1\n",
      "7 cell: 20230622Dish2_H7_3\n",
      "8 cell: 20230620Dish4_K13_4\n",
      "9 cell: 20230622Dish4_M9_6\n",
      "10 cell: 20230621Dish2_F13_3\n",
      "11 cell: 20230622Dish4_L13_5\n",
      "12 cell: 20230622Dish2_H7_6\n",
      "13 cell: 20230622Dish6_O6_4\n",
      "14 cell: 20230622Dish6_O6_3\n",
      "15 cell: 20230622Dish4_L13_7\n",
      "16 cell: 20230622Dish5_N14_7\n",
      "17 cell: 20230622Dish2_H7_5\n",
      "18 cell: 20230620Dish4_O12_1\n",
      "19 cell: 20230622Dish2_H7_2\n",
      "20 cell: 20230622Dish2_H7_9\n",
      "21 cell: 20230620Dish4_O12_4\n",
      "22 cell: 20230622Dish2_H7_4\n",
      "23 cell: 20230620Dish4_O12_6\n",
      "24 cell: 20230620Dish4_K13_7\n",
      "25 cell: 20230621Dish2_F13_2\n",
      "26 cell: 20230620Dish4_O12_2\n",
      "27 cell: 20230620Dish4_K13_5\n",
      "28 cell: 20230621Dish5_H8_3\n",
      "29 cell: 20230622Dish5_N14_8\n",
      "30 cell: 20230621Dish2_F13_1\n",
      "31 cell: 20230622Dish4_M9_2\n",
      "32 cell: 20230622Dish2_H7_7\n",
      "33 cell: 20230620Dish4_O12_3\n",
      "34 cell: 20230622Dish3_M9_6\n",
      "35 cell: 20230622Dish2_J2_10\n",
      "36 cell: 20230620Dish4_K13_6\n"
     ]
    }
   ],
   "source": [
    "# cells\n",
    "if False:\n",
    "    # sequenced single cells\n",
    "    fdn_sub = '/home/yike/phd/cancer_cells_img_seq/figures/batch_202306/background_substraction/'\n",
    "    fdn_seg = '/home/yike/phd/cancer_cells_img_seq/figures/batch_202306/cropped_cell_npz/good/'\n",
    "\n",
    "if True:\n",
    "    # dapi bright cells\n",
    "    fdn_sub = '/home/yike/phd/cancer_cells_img_seq/figures/batch_202306/dapi_background_substraction/'\n",
    "    fdn_seg = '/home/yike/phd/cancer_cells_img_seq/figures/batch_202306/dapi_cropped_cell_npz/'    \n",
    "    \n",
    "features = []\n",
    "for i, fn in enumerate([i for i in os.listdir(fdn_sub) if '.npz' in i]):\n",
    "    print('{} cell: {}'.format(i+1, fn.split('.')[0]))\n",
    "    \n",
    "    feas = extract_features(fdn_sub, fdn_seg, fn)\n",
    "    features.append(feas)\n",
    "features_all = pd.DataFrame(features)\n",
    "\n",
    "# save features as a pickle file\n",
    "with open(fdn_sub + 'bkg_sub_features.pkl', 'wb') as f:\n",
    "    pickle.dump(features_all, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "sunset-minority",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325 414 22.22222222222222%\n",
      "343 414 13.88888888888889%\n",
      "370 414 13.88888888888889%\n",
      "343 451 0.0%\n",
      "370 451 0.0%\n",
      "373 451 2.7777777777777777%\n",
      "343 575 0.0%\n",
      "393 575 25.0%\n",
      "406 575 33.333333333333336%\n",
      "441 575 33.333333333333336%\n",
      "400 594 33.333333333333336%\n",
      "406 594 33.333333333333336%\n",
      "431 594 33.333333333333336%\n",
      "480 594 33.333333333333336%\n",
      "339 575 33.333333333333336%\n",
      "total 0.0%\n"
     ]
    }
   ],
   "source": [
    "# bright dapi cells\n",
    "\n",
    "# check the percentage of cells with positive intensities after background subtraction under each channel\n",
    "df = pd.DataFrame([], index=features_all['image'])\n",
    "for i, wl in enumerate(features_all.loc[0]['wavelengths']):\n",
    "    df['{} {}'.format(str(wl[0]), str(wl[1]))] = [fea[i] for fea in features_all['total_intensity']]\n",
    "    \n",
    "neg = []\n",
    "for i in df.index:\n",
    "    neg.append(sum(1 for n in df.loc[i] if n < 0))\n",
    "df['total'] = neg\n",
    "\n",
    "for col in df.columns:\n",
    "    n = sum(1 for i in df[col] if i < 0)\n",
    "    print('{} {}'.format(col, str(n * 100/36) + '%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "applicable-applicant",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325 414 25.925925925925927%\n",
      "343 414 11.11111111111111%\n",
      "370 414 12.345679012345679%\n",
      "343 451 1.2345679012345678%\n",
      "370 451 2.4691358024691357%\n",
      "373 451 2.4691358024691357%\n",
      "343 575 0.0%\n",
      "393 575 28.395061728395063%\n",
      "406 575 33.333333333333336%\n",
      "441 575 33.333333333333336%\n",
      "400 594 35.80246913580247%\n",
      "406 594 38.27160493827161%\n",
      "431 594 38.27160493827161%\n",
      "480 594 38.27160493827161%\n",
      "339 575 40.74074074074074%\n",
      "total 0.0%\n"
     ]
    }
   ],
   "source": [
    "# sequenced single cells\n",
    "\n",
    "# check the percentage of cells with positive intensities after background subtraction under each channel\n",
    "df = pd.DataFrame([], index=features_all['image'])\n",
    "for i, wl in enumerate(features_all.loc[0]['wavelengths']):\n",
    "    df['{} {}'.format(str(wl[0]), str(wl[1]))] = [fea[i] for fea in features_all['total_intensity']]\n",
    "    \n",
    "neg = []\n",
    "for i in df.index:\n",
    "    neg.append(sum(1 for n in df.loc[i] if n < 0))\n",
    "df['total'] = neg\n",
    "\n",
    "for col in df.columns:\n",
    "    n = sum(1 for i in df[col] if i < 0)\n",
    "    print('{} {}'.format(col, str(n * 100/81) + '%'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-occupation",
   "metadata": {},
   "source": [
    "# combine two extracted feature files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "indie-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "indian-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "feas_fn1 = '/home/yike/phd/cancer_cells_img_seq/figures/batch_202112/segmentation/background_subtraction/bkg_sub_features.pkl'\n",
    "with open(feas_fn1, 'rb') as f:\n",
    "    features1 = pd.read_pickle(f)\n",
    "features1.set_index('image', inplace=True)\n",
    "\n",
    "# change index name\n",
    "batch1 = sc.read_h5ad('/home/yike/phd/cancer_cells_img_seq/data/20220201_NextSeq/exon_filter.h5ad')\n",
    "batch1.obs = batch1.obs[['R1', 'R2', 'batch', 'grid', '#cells', '#feature']]\n",
    "batch1.obs.columns = ['R1', 'R2', 'Batch', 'Grid', 'Cell_number', 'Cell_annotation']\n",
    "batch1.obs = batch1.obs.loc[features1.index]\n",
    "features1.index = [i + '_' + j for (i, j) in zip(batch1.obs['Batch'].tolist(), batch1.obs_names.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "extensive-cursor",
   "metadata": {},
   "outputs": [],
   "source": [
    "feas_fn2 = '/home/yike/phd/cancer_cells_img_seq/figures/batch_202306/background_substraction/bkg_sub_features.pkl'\n",
    "with open(feas_fn2, 'rb') as f:\n",
    "    features2 = pd.read_pickle(f)\n",
    "features2.set_index('image', inplace=True)\n",
    "\n",
    "# change index name\n",
    "batch2 = sc.read_h5ad('/home/yike/phd/cancer_cells_img_seq/data/202306_NextSeq/202307_exon.h5ad')\n",
    "batch2.obs['Batch'] = '3-1'\n",
    "batch2.obs_names = [i + '_' + j for (i, j) in zip(batch2.obs['Batch'].tolist(), batch2.obs_names.tolist())]\n",
    "batch2.obs['batch_index'] = np.array(batch2.obs_names.str.split('_').tolist())[:, 0]\n",
    "features2.index = batch2.obs.reset_index().set_index('batch_index').loc[features2.index]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "seeing-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine and save\n",
    "features = pd.concat([features1, features2])\n",
    "\n",
    "with open('/home/yike/phd/cancer_cells_img_seq/figures/combine_features.pkl', 'wb') as f:\n",
    "    pickle.dump(features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "advised-worcester",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-experiment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-niger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-century",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-nelson",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
